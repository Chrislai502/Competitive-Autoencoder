{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578a73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "Convolutioanl Winner-Take-All Autoencoder TensorFlow implementation.\n",
    "Usage :\n",
    "  ae = ConvWTA(sess)\n",
    "  # 1. to train an Autoencoder\n",
    "  loss = ae.loss(x)\n",
    "  train = optimizer.minimize(loss)\n",
    "  sess.run(train, feed_dict={...})\n",
    "  # 2. to get the sparse codes\n",
    "  h = ae.encoder(x)\n",
    "  sess.run(h, feed_dict={...})\n",
    "  # 3. to get the reconstructed results\n",
    "  y = ae.reconstruct(x)\n",
    "  sess.run(y, feed_dict={...})\n",
    "  # 4. to get the learned features\n",
    "  f = ae.features() # np.float32 array with shape [11, 11, 1, 16]\n",
    "    # 4-1. to train a different number of features\n",
    "    ae = ConvWTA(sess, num_features=32)\n",
    "  # 5. to save & restore the variables\n",
    "  ae.save(save_path)\n",
    "  ae.restore(save_path)\n",
    "Reference: \n",
    "  [1] https://arxiv.org/pdf/1409.2752.pdf\n",
    "\"\"\"\n",
    "\n",
    "class ConvWTA(object):\n",
    "  \"\"\"\n",
    "    Args :\n",
    "      sess : TensorFlow session.\n",
    "      x : Input tensor.\n",
    "  \"\"\"\n",
    "  def __init__(self, sess, num_features=16,  name=\"ConvWTA\"):\n",
    "    self.sess = sess\n",
    "    self.name = name\n",
    "    self.size = [1, 128, 128, num_features]  # ref [1]\n",
    "\n",
    "    self._set_variables()\n",
    "    self.t_vars = tf.get_collection(\n",
    "      tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n",
    "    self.sess.run(tf.variables_initializer(self.t_vars))\n",
    "    self.saver = tf.train.Saver(self.t_vars)\n",
    "      \n",
    "  def encoder(self, x):\n",
    "    with tf.variable_scope(self.name) as vs:\n",
    "      h = self._conv(x, self.size[1], 5, 5, 1, 1, \"conv_1\")\n",
    "      h = self._conv(h, self.size[2], 5, 5, 1, 1, \"conv_2\")\n",
    "      h = self._conv(h, self.size[3], 5, 5, 1, 1, \"conv_3\")\n",
    "    return h\n",
    "\n",
    "  def _decoder(self, h):\n",
    "    shape = tf.shape(h)\n",
    "    out_shape = tf.stack([shape[0], shape[1], shape[2], 1])\n",
    "    with tf.variable_scope(self.name) as vs:\n",
    "      y = self._deconv(h, out_shape, self.size[0], \n",
    "                       11, 11, 1, 1, \"deconv\", end=True)\n",
    "    return y\n",
    "\n",
    "  def loss(self, x, lifetime_sparsity=0.20):\n",
    "    h = self.encoder(x)\n",
    "    h, winner = self._spatial_sparsity(h)\n",
    "    h = self._lifetime_sparsity(h, winner, lifetime_sparsity)\n",
    "    y = self._decoder(h)\n",
    "\n",
    "    return tf.reduce_sum(tf.square(y - x))\n",
    "\n",
    "  def reconstruct(self, x):\n",
    "    h = self.encoder(x)\n",
    "    h, _ = self._spatial_sparsity(h)\n",
    "    y = self._decoder(h)\n",
    "    return y\n",
    "    \n",
    "  def _set_variables(self):\n",
    "    with tf.variable_scope(self.name) as vs:\n",
    "      self._conv_var(self.size[0], self.size[1],  5,  5, \"conv_1\")\n",
    "      self._conv_var(self.size[1], self.size[2],  5,  5, \"conv_2\")\n",
    "      self._conv_var(self.size[2], self.size[3],  5,  5, \"conv_3\")\n",
    "      self.f, _ = self._deconv_var(\n",
    "        self.size[-1], self.size[0], 11, 11, \"deconv\")\n",
    "    \n",
    "  def _conv_var(self, in_dim, out_dim, k_h, k_w, name, stddev=0.1):\n",
    "    with tf.variable_scope(name) as vs:\n",
    "      k = tf.get_variable('filter',\n",
    "          [k_h, k_w, in_dim, out_dim],\n",
    "          initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "      b = tf.get_variable('biases', [out_dim],\n",
    "        initializer=tf.constant_initializer(0.0001))\n",
    "    return k, b\n",
    "\n",
    "  def _deconv_var(self, in_dim, out_dim, k_h, k_w, name, stddev=0.1):\n",
    "    with tf.variable_scope(name) as vs:\n",
    "      k = tf.get_variable('filter',\n",
    "          [k_h, k_w, out_dim, in_dim],\n",
    "          initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "      b = tf.get_variable('biases', [out_dim],\n",
    "        initializer=tf.constant_initializer(0.0001))\n",
    "    return k, b\n",
    "\n",
    "  def _conv(self, x, out_dim, \n",
    "            k_h, k_w, s_h, s_w, name, end=False):\n",
    "    with tf.variable_scope(name, reuse=True) as vs:\n",
    "      k = tf.get_variable('filter')\n",
    "      b = tf.get_variable('biases')\n",
    "      conv = tf.nn.conv2d(x, k, [1, s_h, s_w, 1], \"SAME\") + b\n",
    "    return conv if end else tf.nn.relu(conv)\n",
    "\n",
    "  def _deconv(self, x, out_shape, out_dim,\n",
    "            k_h, k_w, s_h, s_w, name, end=False):\n",
    "    with tf.variable_scope(name, reuse=True) as vs:\n",
    "      k = tf.get_variable('filter')\n",
    "      b = tf.get_variable('biases')\n",
    "      deconv = tf.nn.conv2d_transpose(\n",
    "        x, k, out_shape, [1, s_h, s_w, 1], \"SAME\") + b\n",
    "    return deconv if end else tf.nn.relu(deconv)\n",
    "\n",
    "  def _spatial_sparsity(self, h):\n",
    "    shape = tf.shape(h)\n",
    "    n = shape[0]\n",
    "    c = shape[3]\n",
    "\n",
    "    h_t = tf.transpose(h, [0, 3, 1, 2]) # n, c, h, w\n",
    "    h_r = tf.reshape(h_t, tf.stack([n, c, -1])) # n, c, h*w\n",
    "\n",
    "    th, _ = tf.nn.top_k(h_r, 1) # n, c, 1\n",
    "    th_r = tf.reshape(th, tf.stack([n, 1, 1, c])) # n, 1, 1, c\n",
    "    drop = tf.where(h < th_r, \n",
    "      tf.zeros(shape, tf.float32), tf.ones(shape, tf.float32))\n",
    "\n",
    "    # spatially dropped & winner\n",
    "    return h*drop, tf.reshape(th, tf.stack([n, c])) # n, c\n",
    "    \n",
    "  def _lifetime_sparsity(self, h, winner, rate):\n",
    "    shape = tf.shape(winner)\n",
    "    n = shape[0]\n",
    "    c = shape[1]\n",
    "    k = tf.cast(rate * tf.cast(n, tf.float32), tf.int32)\n",
    "\n",
    "    winner = tf.transpose(winner) # c, n\n",
    "    th_k, _ = tf.nn.top_k(winner, k) # c, k\n",
    "\n",
    "    shape_t = tf.stack([c, n])\n",
    "    drop = tf.where(winner < th_k[:,k-1:k], # c, n\n",
    "      tf.zeros(shape_t, tf.float32), tf.ones(shape_t, tf.float32))\n",
    "    drop = tf.transpose(drop) # n, c\n",
    "    return h * tf.reshape(drop, tf.stack([n, 1, 1, c]))\n",
    "\n",
    "  def features(self): \n",
    "    return self.sess.run(self.f)\n",
    "    \n",
    "  def save(self, ckpt_path):\n",
    "    self.saver.save(self.sess, ckpt_path)\n",
    "\n",
    "  def restore(self, ckpt_path):\n",
    "    self.saver.restore(self.sess, ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
