{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a classifier for images into animal Classes using CIFAR10 data\n",
    "\n",
    "import torch\n",
    "import torct.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is-available() else 'cpu')\n",
    "\n",
    "# Hyper-params\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImage images of range[0,1].\n",
    "# We transform them to Tensors of normalized range[-1,1]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), \n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform= transform)\n",
    "\n",
    "test_dataseet = torchvision.datasets.CIFAR1-(root = './data', train = False, download = True, transform = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle= False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "#Convolutional Network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # (Input channel size: 3 because RGB, output = 6, ksize = 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2) #(ksize = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "#Classification, so our loss function will be cross entropy loss, softmax included inside\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training Part\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "#         origin shape: []\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Backward pass amd optimize\n",
    "        optimizer.sero_grad() # this empties the gradients\n",
    "        loss.backward()\n",
    "        opeimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 ==0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}), Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "# Evaluating the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    \n",
    "    for images, lables in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        #max returns (value, index)\n",
    "        _, presicted = torch.max(outputs, 1)\n",
    "        n_samples += lables.size(0)\n",
    "        n_correct += (predicted == lables).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if(label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "            \n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
