{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d3835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "''' Parameters (CHange Anything Here!) '''\n",
    "transform = transforms.ToTensor()\n",
    "batch_size = 3\n",
    "#lifetime Sparcity\n",
    "k_percent = 5\n",
    "\n",
    "\n",
    "''' Code Starts Here '''\n",
    "#Data MNIST\n",
    "mnist_data = datasets.MNIST(root='./data', train = True, download = True, transform = transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset= mnist_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# testing model\n",
    "''' Conv 2d Layer \n",
    "#         Accessible Variables: .weights(Tensor), .bias(Tensor)\n",
    "#         parameters :\n",
    "#         torch.nn.Conv2d(in_channels, out_channels, \n",
    "#                         kernel_size, stride=1, padding=0, \n",
    "#                         dilation=1, groups=1, bias=True, \n",
    "#                         padding_mode='zeros')\n",
    "'''\n",
    "class Autoencoder_Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Image size:N, 28, 28\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3, stride=1) # stride 2 will reduce size by half (W - F + 2P)/\n",
    "        self.decoder = nn.Linear(2 * 26 * 26, 28*28) # input items, output items\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.conv1(x) # encode, output: torch.Size([3, 2, 26, 26])\n",
    "#         x = encoded.view(-1, 2 * 26 * 26) # flattening it out\n",
    "#         decoded = self.decoder(x) \n",
    "#         decoded = decoded.view(3, 1, 28, 28) # converting it back to same format as input\n",
    "#         #encoded is the output of the layer\n",
    "        return encoded\n",
    "    \n",
    "    # With ReLU\n",
    "    def forward(self, x, relu = True):\n",
    "        encoded = F.relu(self.conv1(x)) # encode, output: torch.Size([3, 2, 26, 26])\n",
    "        x = encoded.view(-1, 2 * 26 * 26) # flattening it out\n",
    "        decoded = self.decoder(x) \n",
    "        decoded = decoded.view(3, 1, 28, 28) # converting it back to same format as input\n",
    "        #encoded is the output of the layer\n",
    "        return decoded\n",
    "    \n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self,yhat,y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss\n",
    "    \n",
    "model = Autoencoder_Test()\n",
    "generator = model.parameters() #(returns a generator)\n",
    "criterion = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1689a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Sum of the feature maps(Should have batch_size values): \n",
      " tensor([[ 30.3885, -56.0443],\n",
      "        [ 24.0721, -60.3822],\n",
      "        [ 24.6637, -59.8583]])\n",
      "\n",
      "\n",
      "Maximum Values:  [ 30.38851  -56.044304] \n",
      "Batch Location Indexes:  [0 0]\n",
      "SortedDict({-56.044304: [(0, 1)], 30.38851: [(0, 0)]})\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0321,  0.1935,  0.3018],\n",
      "          [-0.1194, -0.0227, -0.0005],\n",
      "          [ 0.3243, -0.1935, -0.2744]]],\n",
      "\n",
      "\n",
      "        [[[-0.0840,  0.2898,  0.2096],\n",
      "          [-0.1427, -0.2340, -0.0550],\n",
      "          [-0.1770,  0.0344,  0.3196]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Batch Training loop\n",
    "# Hidden Units here is to be defined as feature maps\n",
    "# Spatial Sparsity: For every feature Filter, after batch prediction, pick the highest output activity winner and set the rest to 0\n",
    "# Lifetime Sparsity: For every feature Filter, after batch prediction, pick the hightst k% of all the winners picked in Spatial Sparsity\n",
    "from sortedcontainers import SortedList, SortedDict\n",
    "\n",
    "num_epochs = 1\n",
    "sorted_list = SortedList()\n",
    "winnersMap = {}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "#     for (img, labels) in data_loader:\n",
    "    img, labels = dataiter.next()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # First feedforward to get the k% of winners\n",
    "        feature_map = model(img) # returns the feature maps of all batch examples in order\n",
    "\n",
    "        # Summing up the activation maps to find the maximum activation hidden map from the the batch\n",
    "        summation = torch.sum(feature_map, (2, 3)) # reduce the 3rd and 4th dimension of the tensor. Summation is a 2-dim tensor\n",
    "        print(\"\\n\\n Sum of the feature maps(Should have batch_size values): \\n\", summation)\n",
    "\n",
    "        # batch_idx: torch tensor with the max batch index, size = num_features\n",
    "        # max_val:   torch tensor with the max_val for each batch, size = num_features\n",
    "        max_val, batch_idx = torch.max(summation, 0) # returns a tensor with the size of number of features\n",
    "        max_val = max_val.numpy()\n",
    "        batch_idx = batch_idx.numpy()\n",
    "        print(\"\\n\\nMaximum Values: \", max_val, \"\\nBatch Location Indexes: \", batch_idx)\n",
    "\n",
    "        # where feature_num starts from 0\n",
    "        for feature_num, max_values in enumerate(max_val):\n",
    "        # Have to store list of tuples in sorted dict where tuples = (feature no., index)\n",
    "        # if there is more than one value in this list, then backprop have to iterate through the list\n",
    "            if winnersMap.get(max_values) == None:\n",
    "                winnersMap[max_values] = [(feature_num, batch_idx[feature_num])]\n",
    "            else:\n",
    "                winnersMap[max_values] = winnersMap[max_values].append((feature_num, batch_idx[feature_num]))\n",
    "\n",
    "        sorted_dict = SortedDict(winnersMap) # store and the keys sort Automatically\n",
    "        print(sorted_dict)\n",
    "        \n",
    "        # Constructing the new Tensor with only the k% of the winners\n",
    "        # This tensor.... requires_grad = True?\n",
    "        \n",
    "        \n",
    "    # 2nd feedforward bias with only the k% of winner batches with relu\n",
    "    k_forward = model(k_percent_winners, True)\n",
    "    loss.backward()\n",
    "    loss = criterion(decoded, img)+\n",
    "#     layers = model.children()\n",
    "#     hidden = next(layers)\n",
    "#     print(next(hidden.parameters()))\n",
    "# #     for params in hidden.parameters():\n",
    "# #         print(params.grad)\n",
    "        \n",
    "# #         for param in child.parameters():\n",
    "# #             if\n",
    "# #             param.grad = 0   \n",
    "\n",
    "    # Update weights\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "# Plan reduce 3 batches into 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c444c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
