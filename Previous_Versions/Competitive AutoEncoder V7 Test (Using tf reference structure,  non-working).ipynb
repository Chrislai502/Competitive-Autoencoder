{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193ce4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "''' Parameters (CHange Anything Here!) '''\n",
    "transform = transforms.ToTensor()\n",
    "batch_size = 3\n",
    "# lifetime Sparcity\n",
    "k_percent = 5\n",
    "\n",
    "\n",
    "''' Code Starts Here '''\n",
    "# Data MNIST\n",
    "mnist_data = datasets.MNIST(root='./data', train = True, download = True, transform = transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset= mnist_data, batch_size = batch_size, shuffle = True)\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# testing model\n",
    "''' Conv 2d Layer \n",
    "#         Accessible Variables: .weights(Tensor), .bias(Tensor)\n",
    "#         parameters :\n",
    "#         torch.nn.Conv2d(in_channels, out_channels, \n",
    "#                         kernel_size, stride=1, padding=0, \n",
    "#                         dilation=1, groups=1, bias=True, \n",
    "#                         padding_mode='zeros')\n",
    "'''\n",
    "# CONV-WTA CRITERIA\n",
    "# - zero padded, so that each feature map has the same size as the input\n",
    "# - hidden representation is mapped linearly to the output using a deconvolution operation\n",
    "# - Parameters are optimized to reduce the mean squared error MSE\n",
    "# - Conv layer is 5 x5, DECONVOLUTION layer is using filters of 11x 11\n",
    "### In this implementation, I will not use deconvolution, but transpose convolution to ease process\n",
    "class Autoencoder_Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Image size:N, 28, 28\n",
    "        self.conv1      = nn.Conv2d(1, 2, 5, stride=1, padding = 2) \n",
    "        self.transConv1 = nn.ConvTranspose2d(in_channels=2, out_channels=3, kernel_size=11, stride =1, padding = 5) # padding will decrease output size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.conv1(x) # encode, output: torch.Size([3, 2, 26, 26])\n",
    "        hidden, winners = self.spatial_sparsity_(encoded)\n",
    "        hidden = self.lifetime_sparsity_(hidden, winner, k_percent = 0.1)\n",
    "        decoded = self.transConv1(hidden)\n",
    "        return decoded\n",
    "    \n",
    "    # Spatial Sparsity reconstructs the activation map, remain only one winner neuron of each feature map and rest to 0\n",
    "    # with torch.no_grad() temporarily sets all of the requires_grad flags to false\n",
    "    def spatial_sparsity_(self, hiddenMaps):\n",
    "        with torch.no_grad():\n",
    "            shape = hiddenMaps.shape  #torch.Size([batch_size, feature_num, 26, 26])\n",
    "            n_batches = shape[0]\n",
    "            n_features = shape[1]\n",
    "            size = shape[2]\n",
    "            \n",
    "            # Step 1: flatten it out, find max_vals\n",
    "            flatten = hiddenMaps.view(n_batches, n_features, -1)\n",
    "            max_val, batch_idx = torch.max(flatten, 0) # max_val return size[n_batches, n_features]\n",
    "            \n",
    "            # Step 2: creating \"drop\" Array to be multiplied into featureMaps, dropping loser values\n",
    "            maxval, _ = torch.max(flatten, 2)\n",
    "            maxval_p = torch.reshape(maxval, (n_batches, n_features, 1, 1))\n",
    "            drop = torch.where(hiddenMaps < maxval_p, \n",
    "                               torch.zeros((n_batches, n_features, size, size)), \n",
    "                               torch.ones((n_batches,n_features2, size, size)))\n",
    "            \n",
    "            return hiddenMaps*drop, maxval\n",
    "    # Only retain the top-k percent of the winners for every feature. The rest will be zeroed out\n",
    "    def lifetime_sparsity_(self, hiddenMaps, maxval, k_percent):\n",
    "        with torch.no_grad():\n",
    "            shape = hiddenMaps.shape  #torch.Size([batch_size, feature_num, 26, 26])\n",
    "            n_batches = shape[0]\n",
    "            n_features = shape[1]\n",
    "            size = shape[2]\n",
    "            k = math.floor(n_batches * k_percent)\n",
    "\n",
    "            top_k, _ = torch.topk(maxval, k, 0) #c, k\n",
    "\n",
    "            # Step 2: creating \"drop\" Array to be multiplied into featureMaps, dropping loser values\n",
    "            drop = torch.where(maxval < top_k[k-1:k, :],  \n",
    "                               torch.zeros((n_batches, n_features)), \n",
    "                               torch.ones((n_batches, n_features)))\n",
    "\n",
    "            # drop = drop.transpose(0, 1)\n",
    "            # dropping all them loser batches to zero\n",
    "            return hiddenMaps * drop.reshape(n_batches, n_features, 1, 1)\n",
    "    \n",
    "model = Autoencoder_Test()\n",
    "generator = model.parameters() #(returns a generator)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "868290e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 15,  31,  47],\n",
      "        [ 63,  79,  95],\n",
      "        [111, 127, 143],\n",
      "        [159, 175, 191]])\n",
      "tensor([[159, 175, 191],\n",
      "        [111, 127, 143],\n",
      "        [ 63,  79,  95]])\n",
      "tensor([[ 15,  63, 111, 159],\n",
      "        [ 31,  79, 127, 175],\n",
      "        [ 47,  95, 143, 191]])\n",
      "tensor([[63],\n",
      "        [79],\n",
      "        [95]])\n",
      "tensor([[0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[[[0.]],\n",
      "\n",
      "         [[0.]],\n",
      "\n",
      "         [[0.]]],\n",
      "\n",
      "\n",
      "        [[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]],\n",
      "\n",
      "\n",
      "        [[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]],\n",
      "\n",
      "\n",
      "        [[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[ 48.,  49.,  50.,  51.],\n",
       "          [ 52.,  53.,  54.,  55.],\n",
       "          [ 56.,  57.,  58.,  59.],\n",
       "          [ 60.,  61.,  62.,  63.]],\n",
       "\n",
       "         [[ 64.,  65.,  66.,  67.],\n",
       "          [ 68.,  69.,  70.,  71.],\n",
       "          [ 72.,  73.,  74.,  75.],\n",
       "          [ 76.,  77.,  78.,  79.]],\n",
       "\n",
       "         [[ 80.,  81.,  82.,  83.],\n",
       "          [ 84.,  85.,  86.,  87.],\n",
       "          [ 88.,  89.,  90.,  91.],\n",
       "          [ 92.,  93.,  94.,  95.]]],\n",
       "\n",
       "\n",
       "        [[[ 96.,  97.,  98.,  99.],\n",
       "          [100., 101., 102., 103.],\n",
       "          [104., 105., 106., 107.],\n",
       "          [108., 109., 110., 111.]],\n",
       "\n",
       "         [[112., 113., 114., 115.],\n",
       "          [116., 117., 118., 119.],\n",
       "          [120., 121., 122., 123.],\n",
       "          [124., 125., 126., 127.]],\n",
       "\n",
       "         [[128., 129., 130., 131.],\n",
       "          [132., 133., 134., 135.],\n",
       "          [136., 137., 138., 139.],\n",
       "          [140., 141., 142., 143.]]],\n",
       "\n",
       "\n",
       "        [[[144., 145., 146., 147.],\n",
       "          [148., 149., 150., 151.],\n",
       "          [152., 153., 154., 155.],\n",
       "          [156., 157., 158., 159.]],\n",
       "\n",
       "         [[160., 161., 162., 163.],\n",
       "          [164., 165., 166., 167.],\n",
       "          [168., 169., 170., 171.],\n",
       "          [172., 173., 174., 175.]],\n",
       "\n",
       "         [[176., 177., 178., 179.],\n",
       "          [180., 181., 182., 183.],\n",
       "          [184., 185., 186., 187.],\n",
       "          [188., 189., 190., 191.]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def _lifetime_sparsity(self, h, winner, rate):\n",
    "#     shape = tf.shape(winner)\n",
    "#     n = shape[0]\n",
    "#     c = shape[1]\n",
    "#     k = tf.cast(rate * tf.cast(n, tf.float32), tf.int32)\n",
    "\n",
    "#     winner = tf.transpose(winner) # c, n\n",
    "#     th_k, _ = tf.nn.top_k(winner, k) # c, k\n",
    "\n",
    "#     shape_t = tf.stack([c, n])\n",
    "#     drop = tf.where(winner < th_k[:,k-1:k], # c, n\n",
    "#       tf.zeros(shape_t, tf.float32), tf.ones(shape_t, tf.float32))\n",
    "#     drop = tf.transpose(drop) # n, c\n",
    "#     return h * tf.reshape(drop, tf.stack([n, 1, 1, c]))\n",
    "import math\n",
    "k_percent = 0.5\n",
    "hiddenMaps = torch.arange(4*3*4*4).view(4,3,4,4)\n",
    "# print(hiddenMaps)\n",
    "shape = hiddenMaps.shape  #torch.Size([batch_size, feature_num, 26, 26])\n",
    "n_batches = shape[0]\n",
    "n_features = shape[1]\n",
    "size = shape[2]\n",
    "k = math.floor(n_batches * k_percent)\n",
    "# k = torch.tensor([2])\n",
    "\n",
    "# from spatial sparsity\n",
    "flatten = hiddenMaps.view(n_batches, n_features, -1)\n",
    "maxval, _ = torch.max(flatten, 2)\n",
    "print(maxval)\n",
    "\n",
    "# Step 1: pick the max of dim-0, along the batch axis\n",
    "# if input size is (n, c), returns (k, c) if operate over dim-0\n",
    "# maxval_t = torch.transpose(maxval, 0, 1) # c, n\n",
    "# print(maxval_t)\n",
    "# top_k, _ = torch.topk(maxval_t, k.item(), 1) #c, k\n",
    "# print(top_k)\n",
    "# print(top_k[:,k-1:k])\n",
    "top_k, _ = torch.topk(maxval, k, 0) #k, c, maxval: n, c\n",
    "print(top_k)\n",
    "# print(top_k)\n",
    "maxval_t = torch.transpose(maxval, 0,1) \n",
    "top_k = torch.transpose(top_k, 0,1)\n",
    "# print(top_k)\n",
    "# print(maxval_t)\n",
    "print(maxval_t)\n",
    "print(top_k[:, k-1:k])\n",
    "# Step 2: creating \"drop\" Array to be multiplied into featureMaps, dropping loser values\n",
    "drop = torch.where(maxval_t < top_k[:, k-1:k],  \n",
    "                   torch.zeros((n_features, n_batches)), \n",
    "                   torch.ones((n_features, n_batches)))\n",
    "\n",
    "print(drop)\n",
    "print(drop.transpose(0, 1))\n",
    "drop = drop.transpose(0, 1)\n",
    "print(drop.reshape(n_batches, n_features, 1, 1))\n",
    "\n",
    "# dropping all them loser batches to zero\n",
    "# hidden map size = (4,3,4,4), drop size = (4, 3, 1, 1)\n",
    "hiddenMaps * drop.reshape(n_batches, n_features, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7ec80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  0.],\n",
      "          [99.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.],\n",
      "          [96.,  0.]],\n",
      "\n",
      "         [[ 0., 97.],\n",
      "          [ 0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.],\n",
      "          [98.,  0.]],\n",
      "\n",
      "         [[95.,  0.],\n",
      "          [ 0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.],\n",
      "          [ 0., 90.]]],\n",
      "\n",
      "\n",
      "        [[[ 0., 89.],\n",
      "          [ 0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.],\n",
      "          [93.,  0.]],\n",
      "\n",
      "         [[ 0., 94.],\n",
      "          [ 0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.],\n",
      "          [91.,  0.]],\n",
      "\n",
      "         [[88.,  0.],\n",
      "          [ 0.,  0.]],\n",
      "\n",
      "         [[92.,  0.],\n",
      "          [ 0.,  0.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.],\n",
       "          [99.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [96.,  0.]],\n",
       "\n",
       "         [[ 0., 97.],\n",
       "          [ 0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.],\n",
       "          [98.,  0.]],\n",
       "\n",
       "         [[95.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [ 0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0., 94.],\n",
       "          [ 0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [ 0.,  0.]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "k_percent = 0.5\n",
    "# hiddenMaps = torch.arange(4*3*2*2).view(4,3,2,2)\n",
    "\n",
    "# Four batches , 3 featureMaps generated per batch\n",
    "\n",
    "# Batch 1\n",
    "hiddenMaps = torch.tensor([[[[0,   1],\n",
    "                             [99,  3]],\n",
    "                            \n",
    "                            [[4,   5],\n",
    "                             [96,  7]],\n",
    "\n",
    "                            [[8,  97],\n",
    "                             [10, 5]]],\n",
    "\n",
    "# Batch 2\n",
    "                           [[[12, 13],\n",
    "                             [98, 15]],\n",
    "\n",
    "                            [[95, 17],\n",
    "                             [18, 19]],\n",
    "\n",
    "                            [[20, 21],\n",
    "                             [22, 90]]],\n",
    "\n",
    "# Batch 3\n",
    "                           [[[24, 89],\n",
    "                             [26, 27]],\n",
    "\n",
    "                            [[28, 29],\n",
    "                             [93, 31]],\n",
    "\n",
    "                            [[32, 94],\n",
    "                             [34, 35]]],\n",
    "\n",
    "# Batch 4\n",
    "                           [[[36, 37],\n",
    "                             [91, 39]],\n",
    "\n",
    "                            [[88, 41],\n",
    "                             [42, 43]],\n",
    "\n",
    "                            [[92, 45],\n",
    "                             [46, 47]]]])\n",
    "# print(hiddenMaps)\n",
    "spatial = hiddenMaps.clone()\n",
    "shape = hiddenMaps.shape  #torch.Size([batch_size, feature_num, 26, 26])\n",
    "n_batches = shape[0]\n",
    "n_features = shape[1]\n",
    "size = shape[2]\n",
    "k = 2\n",
    "# k = torch.tensor([2])\n",
    "\n",
    "# from spatial sparsity\n",
    "flatten = hiddenMaps.view(n_batches, n_features, -1)\n",
    "maxval, _ = torch.max(flatten, 2)\n",
    "maxval_p = torch.reshape(maxval, (n_batches, n_features, 1, 1))\n",
    "drop = torch.where(hiddenMaps < maxval_p, \n",
    "                   torch.zeros((n_batches, n_features, size, size)), \n",
    "                   torch.ones((n_batches,n_features, size, size)))\n",
    "spatial.data = hiddenMaps.data*drop.data\n",
    "print(spatial)\n",
    "# Step 1: pick the max of dim-0, along the batch axis\n",
    "# if input size is (n, c), returns (k, c) if operate over dim-0\n",
    "# maxval_t = torch.transpose(maxval, 0, 1) # c, n\n",
    "# print(maxval_t)\n",
    "# top_k, _ = torch.topk(maxval_t, k.item(), 1) #c, k\n",
    "# print(top_k)\n",
    "# print(top_k[:,k-1:k])\n",
    "top_k, _ = torch.topk(maxval, k, 0) #k, c, maxval: n, c\n",
    "# print(top_k)\n",
    "# print(top_k)\n",
    "# print(top_k)\n",
    "# print(top_k[k-1:k,: ])\n",
    "# temp = torch.tensor([[64, 79, 95]])\n",
    "# Step 2: creating \"drop\" Array to be multiplied into featureMaps, dropping loser values\n",
    "drop = torch.where(maxval < top_k[k-1:k,: ],  \n",
    "                   torch.zeros((n_batches, n_features)), \n",
    "                   torch.ones((n_batches, n_features)))\n",
    "# print(drop)\n",
    "# dropping all them loser batches to zero\n",
    "# hidden map size = (4,3,4,4), drop size = (4, 3, 1, 1)\n",
    "spatial * drop.reshape(n_batches, n_features, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51a12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2,  3],\n",
      "          [ 4,  5,  6,  7],\n",
      "          [ 8,  9, 10, 11],\n",
      "          [12, 13, 14, 15]],\n",
      "\n",
      "         [[16, 17, 18, 19],\n",
      "          [20, 21, 22, 23],\n",
      "          [24, 25, 26, 27],\n",
      "          [28, 29, 30, 31]]],\n",
      "\n",
      "\n",
      "        [[[32, 33, 34, 35],\n",
      "          [36, 37, 38, 39],\n",
      "          [40, 41, 42, 43],\n",
      "          [44, 45, 46, 47]],\n",
      "\n",
      "         [[48, 49, 50, 51],\n",
      "          [52, 53, 54, 55],\n",
      "          [56, 57, 58, 59],\n",
      "          [60, 61, 62, 63]]],\n",
      "\n",
      "\n",
      "        [[[64, 65, 66, 67],\n",
      "          [68, 69, 70, 71],\n",
      "          [72, 73, 74, 75],\n",
      "          [76, 77, 78, 79]],\n",
      "\n",
      "         [[80, 81, 82, 83],\n",
      "          [84, 85, 86, 87],\n",
      "          [88, 89, 90, 91],\n",
      "          [92, 93, 94, 95]]]])\n",
      "tensor([[[[ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 15.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 31.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 47.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 63.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 79.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 95.]]]]) \n",
      " tensor([[15, 31],\n",
      "        [47, 63],\n",
      "        [79, 95]])\n"
     ]
    }
   ],
   "source": [
    "# Spatial Sparsity test:\n",
    "hiddenMaps = torch.arange(3*2*4*4).view(3,2,4,4)\n",
    "shape = hiddenMaps.shape  #torch.Size([batch_size, feature_num, 26, 26])\n",
    "n_batches = shape[0]\n",
    "n_features = shape[1]\n",
    "size = shape[2]\n",
    "\n",
    "# Step 1: flatten it out, find max_vals\n",
    "flatten = hiddenMaps.view(n_batches, n_features, -1)\n",
    "max_val, batch_idx = torch.max(flatten, 0) # max_val return size[n_batches, n_features]\n",
    "\n",
    "# Step 2: creating \"drop\" Array to be multiplied into featureMaps, dropping loser values\n",
    "maxval, _ = torch.max(flatten, 2)\n",
    "maxval_p = torch.reshape(maxval, (n_batches, n_features, 1, 1))\n",
    "drop = torch.where(hiddenMaps < maxval_p, \n",
    "                   torch.zeros((n_batches, n_features, size, size)), \n",
    "                   torch.ones((n_batches,n_features, size, size)))\n",
    "print(hiddenMaps)\n",
    "print(hiddenMaps*drop,\"\\n\", maxval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
